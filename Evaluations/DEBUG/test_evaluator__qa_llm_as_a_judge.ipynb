{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416264ee",
   "metadata": {},
   "source": [
    "# Testing QA Evaluator Implementation\n",
    "\n",
    "This notebook will help test and debug the QA evaluator implementation to ensure it works correctly with Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd50f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\retko\\anaconda3\\envs\\czsu-multi-agent-text-to-sqla\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "from phoenix.evals import OpenAIModel, QA_PROMPT_TEMPLATE, QA_PROMPT_RAILS_MAP, llm_classify\n",
    "\n",
    "# Apply nest_asyncio for better performance\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf61c5",
   "metadata": {},
   "source": [
    "## Test Data Setup\n",
    "\n",
    "First, let's create some test data that follows the expected format for the QA template:\n",
    "- `input`: The question being asked\n",
    "- `reference`: The context/ground truth\n",
    "- `output`: The generated answer to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5228b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "18a3309f-6778-4b4f-8e85-6ebaae937ccc",
       "rows": [
        [
         "0",
         "What is the amount of men in Prague at the end of Q3 2024?",
         "676069",
         "Based on the data, the number of men in Prague at the end of Q3 2024 is 676,069."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the amount of men in Prague at the end...</td>\n",
       "      <td>676069</td>\n",
       "      <td>Based on the data, the number of men in Prague...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input reference  \\\n",
       "0  What is the amount of men in Prague at the end...    676069   \n",
       "\n",
       "                                              output  \n",
       "0  Based on the data, the number of men in Prague...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample test data\n",
    "test_data = pd.DataFrame({\n",
    "    \"input\": [\"What is the amount of men in Prague at the end of Q3 2024?\"],\n",
    "    \"reference\": [\"676069\"],\n",
    "    \"output\": [\"Based on the data, the number of men in Prague at the end of Q3 2024 is 676,069.\"]\n",
    "})\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bead112",
   "metadata": {},
   "source": [
    "## Configure Model\n",
    "\n",
    "Now set up the Azure OpenAI model using your credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d715c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model\n",
    "model = OpenAIModel(\n",
    "    model=\"gpt-4o__test1\",  # Azure deployment name\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14692def",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Run the evaluation using the Phoenix LLM classify function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6746920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:02<00:00 |  2.63s/it\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "rails = list(QA_PROMPT_RAILS_MAP.values())\n",
    "try:\n",
    "    results = llm_classify(\n",
    "        data=test_data,\n",
    "        template=QA_PROMPT_TEMPLATE,\n",
    "        model=model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True\n",
    "    )\n",
    "    results\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754042ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                        explanation exceptions  \\\n",
      "0  correct  To determine if the answer is correct, we comp...         []   \n",
      "\n",
      "  execution_status  execution_seconds  \n",
      "0        COMPLETED            1.62129  \n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038aa550",
   "metadata": {},
   "source": [
    "## Debugging Common Issues\n",
    "\n",
    "If you encounter errors, check these common issues:\n",
    "\n",
    "1. **Template Variable Names**: Ensure DataFrame columns match the template variables exactly\n",
    "2. **API Connectivity**: Verify Azure OpenAI endpoint and credentials are correct\n",
    "3. **Model Availability**: Check if the specified model/deployment exists in your Azure resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2ffc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given a question, an answer and reference text. You must determine whether the\n",
      "given answer correctly answers the question based on the reference text. Here is the data:\n",
      "    [BEGIN DATA]\n",
      "    ************\n",
      "    [Question]: {input}\n",
      "    ************\n",
      "    [Reference]: {reference}\n",
      "    ************\n",
      "    [Answer]: {output}\n",
      "    [END DATA]\n",
      "Your response must be a single word, either \"correct\" or \"incorrect\",\n",
      "and should not contain any text or characters aside from that word.\n",
      "\"correct\" means that the question is correctly and fully answered by the answer.\n",
      "\"incorrect\" means that the question is not correctly or only partially answered by the\n",
      "answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the QA template to verify expected variables\n",
    "print(QA_PROMPT_TEMPLATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czsu-multi-agent-text-to-sqla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
